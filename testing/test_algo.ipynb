{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from LSTM_algo import LSTMAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "# if is_cuda:\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     print(\"GPU is available\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     print(\"GPU not available, CPU used\")\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size -> Sample (63000,), Labels (63000,)\n",
      "Test dataset size -> Sample (27000,), Labels (27000,)\n"
     ]
    }
   ],
   "source": [
    "sample_size = 90000\n",
    "dataset = pd.read_csv(\"../data/reviews_dataset.csv\")\n",
    "dataset = dataset.sample(frac=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset[\"text\"].values[:sample_size], dataset[\"labels\"].values[:sample_size], test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Train dataset size -> Sample {}, Labels {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"Test dataset size -> Sample {}, Labels {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array(['negative','positive']),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vaishanth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishanth/Workspace/ENPM809K/Web-Scraping-And-Contextual-Analysis-of-Reviews/algorithms/LSTM_algo.py:100: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(final_list_train), np.array(final_list_test), onehot_dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset\n",
      "Padded dataset\n",
      "Loaded datasets as tensors\n",
      "Initializng layers\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "device = device\n",
    "\n",
    "lstm = LSTMAnalyzer(no_layers, output_dim,\n",
    "                    hidden_dim, embedding_dim, device, \n",
    "                    batch_size = 50, drop_prob=0.5)\n",
    "lstm.to(device)\n",
    "\n",
    "lstm.process_dataset(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9537/1293570093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/ENPM809K/Web-Scraping-And-Contextual-Analysis-of-Reviews/algorithms/LSTM_algo.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/ENPM809K/Web-Scraping-And-Contextual-Analysis-of-Reviews/algorithms/LSTM_algo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# embeddings and lstm_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape: B x S x Feature   since batch = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;31m#print(embeds.shape)  #[50, 500, 1000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2181\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "lstm.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('env_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e738630b95736c45865af48faa59aeef505c6ed7a9a98240b21d0125ccc52591"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
