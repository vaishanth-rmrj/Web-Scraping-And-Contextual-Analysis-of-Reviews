{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Transformer Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size -> Sample (63000,), Labels (63000,)\n",
      "Test dataset size -> Sample (27000,), Labels (27000,)\n"
     ]
    }
   ],
   "source": [
    "sample_size = 90000\n",
    "dataset = pd.read_csv(\"../../data/reviews_dataset.csv\")\n",
    "dataset = dataset.sample(frac=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset[\"text\"].values[:sample_size], dataset[\"labels\"].values[:sample_size], test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Train dataset size -> Sample {}, Labels {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"Test dataset size -> Sample {}, Labels {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array(['negative','positive']),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
      "   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
      "Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"
     ]
    }
   ],
   "source": [
    "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'\n",
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separator tokens [SEP], ID 102\n",
      "Class tokens [CLS], ID 101\n",
      "Padding tokens [PAD], ID 0\n",
      "Unknown tokens [UNK], ID 100\n"
     ]
    }
   ],
   "source": [
    "# special tokens used in BERT\n",
    "\n",
    "print(\"Separator tokens {}, ID {}\".format(tokenizer.sep_token, tokenizer.sep_token_id))\n",
    "print(\"Class tokens {}, ID {}\".format(tokenizer.cls_token, tokenizer.cls_token_id))\n",
    "print(\"Padding tokens {}, ID {}\".format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "print(\"Unknown tokens {}, ID {}\".format(tokenizer.unk_token, tokenizer.unk_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=32,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  padding='max_length',\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
       "        1111,  123, 2277,  119,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(encoding['input_ids'][0]))\n",
    "encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(encoding['attention_mask'][0]))\n",
    "encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'When',\n",
       " 'was',\n",
       " 'I',\n",
       " 'last',\n",
       " 'outside',\n",
       " '?',\n",
       " 'I',\n",
       " 'am',\n",
       " 'stuck',\n",
       " 'at',\n",
       " 'home',\n",
       " 'for',\n",
       " '2',\n",
       " 'weeks',\n",
       " '.',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "for txt in x_train:\n",
    "  tokens = tokenizer.encode(txt, max_length=512)\n",
    "  token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 256]);\n",
    "plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "    \n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.text.to_numpy(),\n",
    "    targets=df.labels.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "df_train = pd.DataFrame({\"text\": x_train, \"labels\": y_train})\n",
    "df_test = pd.DataFrame({\"text\": x_test, \"labels\": y_test})\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "# val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 260])\n",
      "torch.Size([16, 260])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()\n",
    "\n",
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 436M/436M [00:24<00:00, 17.6MB/s] \n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15884/3205689644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encoding['input_ids'],\n",
    "  attention_mask=encoding['attention_mask']\n",
    ")\n",
    "last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'last_hidden_state'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15884/531411742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpooled_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 260])\n",
      "torch.Size([16, 260])\n"
     ]
    }
   ],
   "source": [
    "input_ids = data['input_ids'].to(device)\n",
    "attention_mask = data['attention_mask'].to(device)\n",
    "print(input_ids.shape) # batch size x seq length\n",
    "print(attention_mask.shape) # batch size x seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model,\n",
    "  data_loader,\n",
    "  loss_fn,\n",
    "  optimizer,\n",
    "  device,\n",
    "  scheduler,\n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      loss = loss_fn(outputs, targets)\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/home/vaishanth/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 5.79 GiB total capacity; 4.05 GiB already allocated; 27.81 MiB free; 4.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3102/2818453940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   )\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train loss {train_loss} accuracy {train_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3102/753578548.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     17\u001b[0m     outputs = model(\n\u001b[1;32m     18\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3102/1176869724.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m      8\u001b[0m     _, pooled_output = self.bert(\n\u001b[1;32m      9\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         )\n\u001b[1;32m   1014\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 5.79 GiB total capacity; 4.05 GiB already allocated; 27.81 MiB free; 4.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(df_train)\n",
    "  )\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    test_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(df_test)\n",
    "  )\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAd6klEQVR4nO3deZRV5Z3u8e8jQxAQZYpBUCEdDQoUUwEOkWCjBknURCVgNLYmynWIxmtiy0onLd3G1QkOzSVOjV4cOrRoa4jDVZPolRhvggJGEVQiKoYS1AIRQUABf/ePs6kcilNVp4Z9atjPZ62z2MN79vm9FNRz9vRuRQRmZpZdezV3AWZm1rwcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAmvTJD0m6R+aum09axgnqaKW9bdK+klTf65ZseT7CKylkbQ5b7Yz8DGwM5n/HxExt/RVNZykccAvI6JfI7ezCjgvIp5ogrLMqrRv7gLMqouIrruma/vlJ6l9ROwoZW2tlf+urDY+NGStxq5DLJKulPQOcIek7pIekVQpaUMy3S/vPQsknZdMnyPpGUnXJW3flHRiA9sOkPS0pE2SnpB0k6Rf1lH/DyS9J2mtpHPzlt8p6afJdK+kDx9Iel/SHyTtJek/gYOAhyVtlvSPSfuTJS1P2i+QdFjedlclf1dLgY8kXSHpgWo1/ULSzAb8OKwNcRBYa/M5oAdwMDCV3L/hO5L5g4CtwI21vH8MsALoBcwA/rckNaDtfwHPAT2B6cC3i6h7X6Av8F3gJkndC7T7AVAB9Ab2B34ERER8G/grcFJEdI2IGZIOBe4BLkvaP0ouKDrmbe8M4KvAfsAvgQmS9oPcXgIwGfjPOmq3Ns5BYK3Np8BVEfFxRGyNiPUR8UBEbImITcA1wJdref9bEXFbROwE7gL6kPuFW3RbSQcBo4B/johPIuIZ4KE66t4O/GtEbI+IR4HNwBdraNcHODhp+4eo+UTeZOD/RMTvImI7cB2wN3BUXptZEbE6+btaCzwNTErWTQDWRcSSOmq3Ns5BYK1NZURs2zUjqbOk/5D0lqQPyf2i209Suxre/86uiYjYkkx2rWfbA4D385YBrK6j7vXVjtFvqeFzrwVWAr+V9IakabVs8wDgrbwaP03q6FtLXXcBZyXTZ+G9AcNBYK1P9W/HPyD3zXpMRHQDxibLazrc0xTWAj0kdc5bdmBTbDgiNkXEDyLi88BJwOWSxu9aXa35GnKHxABIDlsdCLydv8lq7/k1UCZpMPA1oFVdgWXpcBBYa7cPufMCH0jqAVyV9gdGxFvAYmC6pI6SjiT3S7vRJH1N0heSX+ofkrtsdtels+8Cn89rfh/wVUnjJXUgF4ofA3+spfZtwP0k5zgi4q9NUbe1bg4Ca+1mkjsuvg5YCDxeos89EzgSWA/8FLiX3C/hxjoEeILcOYQ/ATdHxIJk3b8BP06uEPphRKwgd3jnF+T6fxK5k8mf1PEZdwFD8GEhS/iGMrMmIOle4NWISH2PpLGSk92vAp+LiA+bux5rft4jMGsASaMk/V1yjf8E4BRyx99bNEl7AZcD8xwCtktqQSBpTnLzzLIa1kvSLEkrJS2VNCKtWsxS8DlgAblDOLOACyPiz81aUR0kdSF33uF4SnAuxVqP1A4NSRpL7j/J3RExuMD6icAlwERyN+78r4gYk0oxZmZWo9T2CCLiaeD9WpqcQi4kIiIWkrv2u09a9ZiZWWHNOehcX3a/2aUiWba2ekNJU8kNJ0CXLl1GDhw4sCQFmpm1FUuWLFkXEb0LrWvOICh0w0/B41QRMRuYDVBeXh6LFy9Osy4zszZH0ls1rWvOq4Yq2P1uzH7k7pQ0M7MSas4geAg4O7l66AhgYzIolpmZlVBqh4Yk3QOMA3op95i+q4AOABFxK7khcyeSG2BrC3Bu4S2ZmVmaUguCiDijjvUBXJzW55tlwfbt26moqGDbtm11N7ZM6NSpE/369aNDhw5Fv8ePqjRrxSoqKthnn33o378/NT9fx7IiIli/fj0VFRUMGDCg6Pd5iAmzVmzbtm307NnTIWAASKJnz5713kN0EJi1cg4By9eQfw8OAjOzjHMQmFmDffDBB9x8880Neu/EiRP54IMPmrYgaxAHgZk1WG1BsHPnzoLLd3n00UfZb7/9UqiqcSKCTz/9tLnLKCkHgZk12LRp03j99dcZNmwYV1xxBQsWLODYY4/lW9/6FkOGDAHg61//OiNHjmTQoEHMnj276r39+/dn3bp1rFq1isMOO4zzzz+fQYMGccIJJ7B169Y9Puvhhx9mzJgxDB8+nOOOO453330XgM2bN3PuuecyZMgQysrKeOCBBwB4/PHHGTFiBEOHDmX8+Nxjn6dPn851111Xtc3BgwezatWqqhouuugiRowYwerVq7nwwgspLy9n0KBBXHXV30btXrRoEUcddRRDhw5l9OjRbNq0iWOOOYYXXnihqs3RRx/N0qVLm+4vOmW+fNSsjfiXh5fz8pqmfdbM4Qd046qTBtW4/mc/+xnLli2r+iW4YMECnnvuOZYtW1Z1+eKcOXPo0aMHW7duZdSoUZx22mn07Nlzt+289tpr3HPPPdx2221885vf5IEHHuCss87arc2XvvQlFi5ciCRuv/12ZsyYwfXXX8/VV1/Nvvvuy0svvQTAhg0bqKys5Pzzz+fpp59mwIABvP9+bQMh56xYsYI77rijag/nmmuuoUePHuzcuZPx48ezdOlSBg4cyOTJk7n33nsZNWoUH374IXvvvTfnnXced955JzNnzuQvf/kLH3/8MWVlZUX/PTc3B4GZNanRo0fvdg37rFmzmD9/PgCrV6/mtdde2yMIBgwYwLBhwwAYOXIkq1at2mO7FRUVTJ48mbVr1/LJJ59UfcYTTzzBvHnzqtp1796dhx9+mLFjx1a16dGjR511H3zwwRxxxBFV8/fddx+zZ89mx44drF27lpdffhlJ9OnTh1GjRgHQrVs3ACZNmsTVV1/Ntddey5w5czjnnHPq/LyWxEFg1kbU9s29lLp06VI1vWDBAp544gn+9Kc/0blzZ8aNG1fwGvfPfOYzVdPt2rUreGjokksu4fLLL+fkk09mwYIFTJ8+Hcgd069+yWShZQDt27ff7fh/fi35db/55ptcd911LFq0iO7du3POOeewbdu2GrfbuXNnjj/+eB588EHuu+8+WtsIyT5HYGYNts8++7Bp06Ya12/cuJHu3bvTuXNnXn31VRYuXNjgz9q4cSN9+/YF4K677qpafsIJJ3DjjTdWzW/YsIEjjzyS3//+97z55psAVYeG+vfvz/PPPw/A888/X7W+ug8//JAuXbqw77778u677/LYY48BMHDgQNasWcOiRYsA2LRpEzt27ADgvPPO49JLL2XUqFFF7YG0JA4CM2uwnj17cvTRRzN48GCuuOKKPdZPmDCBHTt2UFZWxk9+8pPdDr3U1/Tp05k0aRLHHHMMvXr1qlr+4x//mA0bNjB48GCGDh3KU089Re/evZk9ezannnoqQ4cOZfLkyQCcdtppvP/++wwbNoxbbrmFQw89tOBnDR06lOHDhzNo0CC+853vcPTRRwPQsWNH7r33Xi655BKGDh3K8ccfX7VXMXLkSLp168a557a+8TNTe2ZxWvxgGrO/eeWVVzjssMOauwwD1qxZw7hx43j11VfZa6/m/Y5d6N+FpCURUV6ovfcIzMwa6e6772bMmDFcc801zR4CDeGTxWZmjXT22Wdz9tlnN3cZDdb6osvMzJqUg8DMLOMcBGZmGecgMDPLOAeBmZVU165dgdzllqeffnrBNuPGjavz7tyZM2eyZcuWqnkPa91wDgIzaxYHHHAA999/f4PfXz0IWuqw1jVpScNdOwjMrMGuvPLK3Z5HMH36dK6//no2b97M+PHjGTFiBEOGDOHBBx/c472rVq1i8ODBAGzdupUpU6ZQVlbG5MmTdxtrqNBw0LNmzWLNmjUce+yxHHvsscDfhrUGuOGGGxg8eDCDBw9m5syZVZ/n4a4L830EZm3FY9PgnZeadpufGwIn/qzG1VOmTOGyyy7joosuAnIjdj7++ON06tSJ+fPn061bN9atW8cRRxzBySefXOPzdG+55RY6d+7M0qVLWbp0KSNGjKhaV2g46EsvvZQbbriBp556arfhJgCWLFnCHXfcwbPPPktEMGbMGL785S/TvXt3D3ddA+8RmFmDDR8+nPfee481a9bw4osv0r17dw466CAigh/96EeUlZVx3HHH8fbbb1d9sy7k6aefrvqFXFZWttsvt/vuu48RI0YwfPhwli9fzssvv1xrTc888wzf+MY36NKlC127duXUU0/lD3/4A1D8cNdf+cpXGDJkCNdeey3Lly8HcsNdX3zxxVXtunfvzsKFC5tkuOvq/VuxYsUew123b9+eSZMm8cgjj7B9+/YmHe7aewRmbUUt39zTdPrpp3P//ffzzjvvMGXKFADmzp1LZWUlS5YsoUOHDvTv37/g8NP5Cu0t1DQcdG1qGz/Nw10X5j0CM2uUKVOmMG/ePO6///6qq4A2btzIZz/7WTp06MBTTz3FW2+9Ves2xo4dy9y5cwFYtmxZ1XHvmoaDhpqHwB47diy//vWv2bJlCx999BHz58/nmGOOKbo/WRzu2kFgZo0yaNAgNm3aRN++fenTpw8AZ555JosXL6a8vJy5c+cycODAWrdx4YUXsnnzZsrKypgxYwajR48Gah4OGmDq1KmceOKJVSeLdxkxYgTnnHMOo0ePZsyYMZx33nkMHz686P5kcbhrD0Nt1op5GOrsKWa4aw9DbWbWRqU13LVPFpuZtRJpDXftPQKzVq61Hd61dDXk34ODwKwV69SpE+vXr3cYGJALgfXr19OpU6d6vc+HhsxasX79+lFRUUFlZWVzl2ItRKdOnejXr1+93uMgMGvFOnToUHVXq1lD+dCQmVnGpRoEkiZIWiFppaRpBdbvK+lhSS9KWi6p6e6QMDOzoqQWBJLaATcBJwKHA2dIOrxas4uBlyNiKDAOuF5Sx7RqMjOzPaW5RzAaWBkRb0TEJ8A84JRqbQLYR7nRlboC7wM7UqzJzMyqSTMI+gKr8+YrkmX5bgQOA9YALwHfj4g9HtkjaaqkxZIW++oIM7OmlWYQFHoCRfWLnb8CvAAcAAwDbpTUbY83RcyOiPKIKO/du3dT12lmlmlpBkEFcGDefD9y3/zznQv8KnJWAm8CtQ9TaGZmTSrNIFgEHCJpQHICeArwULU2fwXGA0jaH/gi8EaKNZmZWTWp3VAWETskfQ/4DdAOmBMRyyVdkKy/FbgauFPSS+QOJV0ZEevSqsnMzPaU6p3FEfEo8Gi1ZbfmTa8BTkizBjMzq53vLDYzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcalGgSSJkhaIWmlpGk1tBkn6QVJyyX9Ps16zMxsT+3T2rCkdsBNwPFABbBI0kMR8XJem/2Am4EJEfFXSZ9Nqx4zMysszT2C0cDKiHgjIj4B5gGnVGvzLeBXEfFXgIh4L8V6zMysgDSDoC+wOm++IlmW71Cgu6QFkpZIOrvQhiRNlbRY0uLKysqUyjUzy6Y0g0AFlkW1+fbASOCrwFeAn0g6dI83RcyOiPKIKO/du3fTV2pmlmF1BoGkr0lqSGBUAAfmzfcD1hRo83hEfBQR64CngaEN+CwzM2ugYn7BTwFekzRD0mH12PYi4BBJAyR1TLbzULU2DwLHSGovqTMwBnilHp9hZmaNVOdVQxFxlqRuwBnAHZICuAO4JyI21fK+HZK+B/wGaAfMiYjlki5I1t8aEa9IehxYCnwK3B4RyxrfLTMzK5Yiqh+2r6Gh1As4C7iM3Lf2LwCzIuIXqVVXQHl5eSxevLiUH2lm1upJWhIR5YXWFXOO4CRJ84H/C3QARkfEieSO5f+wSSs1M7OSK+aGsknAv0fE0/kLI2KLpO+kU5aZmZVKMUFwFbB214ykvYH9I2JVRDyZWmVmZlYSxVw19N/kTuTusjNZZmZmbUAxQdA+GSICgGS6Y3olmZlZKRUTBJWSTt41I+kUYF16JZmZWSkVc47gAmCupBvJDRuxGig4JpCZmbU+xdxQ9jpwhKSu5O47qPEmMjMza32Keh6BpK8Cg4BOUm4suYj41xTrMjOzEinmhrJbgcnAJeQODU0CDk65LjMzK5FiThYfFRFnAxsi4l+AI9l9VFEzM2vFigmCbcmfWyQdAGwHBqRXkpmZlVIx5wgeTp4tfC3wPLmHy9yWZlFmZlY6tQZB8kCaJyPiA+ABSY8AnSJiYymKMzOz9NV6aCgiPgWuz5v/2CFgZta2FHOO4LeSTtOu60bNzKxNKeYcweVAF2CHpG3kLiGNiOiWamVmZlYSxdxZvE8pCjEzs+ZRZxBIGltoefUH1ZiZWetUzKGhK/KmOwGjgSXA36dSkZmZlVQxh4ZOyp+XdCAwI7WKzMyspIq5aqi6CmBwUxdiZmbNo5hzBL8gdzcx5IJjGPBiijWZmVkJFXOOYHHe9A7gnoj4fynVY2ZmJVZMENwPbIuInQCS2knqHBFb0i3NzMxKoZhzBE8Ce+fN7w08kU45ZmZWasUEQaeI2LxrJpnunF5JZmZWSsUEwUeSRuyakTQS2JpeSWZmVkrFnCO4DPhvSWuS+T7kHl1pZmZtQDE3lC2SNBD4IrkB516NiO2pV2ZmZiVRzMPrLwa6RMSyiHgJ6CrpovRLMzOzUijmHMH5yRPKAIiIDcD5qVVkZmYlVUwQ7JX/UBpJ7YCO6ZVkZmalVMzJ4t8A90m6ldxQExcAj6ValZmZlUwxQXAlMBW4kNzJ4j+Tu3LIzMzagDoPDSUPsF8IvAGUA+OBV4rZuKQJklZIWilpWi3tRknaKen0Ius2M7MmUuMegaRDgSnAGcB64F6AiDi2mA0n5xJuAo4nN3T1IkkPRcTLBdr9nNwhKDMzK7Ha9gheJfft/6SI+FJE/ALYWY9tjwZWRsQbEfEJMA84pUC7S4AHgPfqsW0zM2sitQXBacA7wFOSbpM0ntw5gmL1BVbnzVcky6pI6gt8A7i1tg1JmippsaTFlZWV9SjBzMzqUmMQRMT8iJgMDAQWAP8T2F/SLZJOKGLbhUIjqs3PBK7cNcR1LbXMjojyiCjv3bt3ER9tZmbFKmaIiY+AucBcST2AScA04Ld1vLUCODBvvh+wplqbcmBecptCL2CipB0R8euiqjczs0Yr5vLRKhHxPvAfyasui4BDJA0A3iZ34vlb1bY3YNe0pDuBRxwCZmalVa8gqI+I2CHpe+SuBmoHzImI5ZIuSNbXel7AzMxKI7UgAIiIR4FHqy0rGAARcU6atZiZWWHFjDVkZmZtmIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws41INAkkTJK2QtFLStALrz5S0NHn9UdLQNOsxM7M9pRYEktoBNwEnAocDZ0g6vFqzN4EvR0QZcDUwO616zMyssDT3CEYDKyPijYj4BJgHnJLfICL+GBEbktmFQL8U6zEzswLSDIK+wOq8+YpkWU2+CzxWaIWkqZIWS1pcWVnZhCWamVmaQaACy6JgQ+lYckFwZaH1ETE7Isojorx3795NWKKZmbVPcdsVwIF58/2ANdUbSSoDbgdOjIj1KdZjZmYFpLlHsAg4RNIASR2BKcBD+Q0kHQT8Cvh2RPwlxVrMzKwGqe0RRMQOSd8DfgO0A+ZExHJJFyTrbwX+GegJ3CwJYEdElKdVk5mZ7UkRBQ/bt1jl5eWxePHi5i7DzKxVkbSkpi/avrPYzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8u4VINA0gRJKyStlDStwHpJmpWsXyppRJr1mJnZnlILAkntgJuAE4HDgTMkHV6t2YnAIclrKnBLWvWYmVlhae4RjAZWRsQbEfEJMA84pVqbU4C7I2chsJ+kPinWZGZm1bRPcdt9gdV58xXAmCLa9AXW5jeSNJXcHgPAZkkrmrbUkugFrGvuIkrMfW77stZfaL19PrimFWkGgQosiwa0ISJmA7OboqjmImlxRJQ3dx2l5D63fVnrL7TNPqd5aKgCODBvvh+wpgFtzMwsRWkGwSLgEEkDJHUEpgAPVWvzEHB2cvXQEcDGiFhbfUNmZpae1A4NRcQOSd8DfgO0A+ZExHJJFyTrbwUeBSYCK4EtwLlp1dMCtOpDWw3kPrd9WesvtME+K2KPQ/JmZpYhvrPYzCzjHARmZhnnIGhCknpI+p2k15I/u9fQrq6hN34oKST1Sr/qhmtsfyVdK+nVZHiR+ZL2K1nx9dSY4VLqem9L1dA+SzpQ0lOSXpG0XNL3S199wzR2WBxJ7ST9WdIjpau6CUSEX030AmYA05LpacDPC7RpB7wOfB7oCLwIHJ63/kByJ9jfAno1d5/S7C9wAtA+mf55ofe3hFddP7OkzUTgMXL3xhwBPFvse1viq5F97gOMSKb3Af7S1vuct/5y4L+AR5q7P/V5eY+gaZ0C3JVM3wV8vUCbuobe+HfgHylwY10L1Kj+RsRvI2JH0m4huftIWqLGDJdSzHtbogb3OSLWRsTzABGxCXiF3IgBLV2jhsWR1A/4KnB7KYtuCg6CprV/JPdBJH9+tkCbmobVQNLJwNsR8WLahTaRRvW3mu+Q+6bVEhXTh5raFNv/lqYxfa4iqT8wHHi26Utsco3t80xyX+I+Tam+1KQ5xESbJOkJ4HMFVv1TsZsosCwkdU62cUJDa0tDWv2t9hn/BOwA5tavupJpzHApRQ2j0gI1eogYSV2BB4DLIuLDJqwtLQ3us6SvAe9FxBJJ45q6sLQ5COopIo6raZ2kd3ftGie7i+8VaFbTsBp/BwwAXpS0a/nzkkZHxDtN1oF6SrG/u7bxD8DXgPGRHGRtgRozXErHIt7bEjVqiBhJHciFwNyI+FWKdTalxvT5dOBkSROBTkA3Sb+MiLNSrLfpNPdJirb0Aq5l95OnMwq0aQ+8Qe6X/q4TUoMKtFtFyz9Z3Kj+AhOAl4Hezd2XOvpZ58+M3LHh/JOIz9Xn593SXo3ss4C7gZnN3Y9S9blam3G0spPFzV5AW3oBPYEngdeSP3skyw8AHs1rN5HclRSvA/9Uw7ZaQxA0qr/khhZZDbyQvG5t7j7V0tc9+gBcAFyQTIvcg5heB14Cyuvz826Jr4b2GfgSuUMqS/N+thObuz9p/5zzttHqgsBDTJiZZZyvGjIzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJhVI2mnpBfyXk02Yqik/pKWNdX2zJqC7yw229PWiBjW3EWYlYr3CMyKJGmVpJ9Lei55fSFZfrCkJ5Px6Z+UdFCyfP/kOQsvJq+jkk21k3RbMlb/byXt3WydMsNBYFbI3tUODU3OW/dhRIwGbiQ32iTJ9N0RUUZu4LxZyfJZwO8jYigwAlieLD8EuCkiBgEfAKel2huzOvjOYrNqJG2OiK4Flq8C/j4i3kgGVXsnInpKWgf0iYjtyfK1EdFLUiXQLyI+zttGf+B3EXFIMn8l0CEiflqCrpkV5D0Cs/qJGqZralPIx3nTO/G5OmtmDgKz+pmc9+efkuk/AlOS6TOBZ5LpJ4ELoepZtt1KVaRZffibiNme9pb0Qt784xGx6xLSz0h6ltyXqDOSZZcCcyRdAVQC5ybLvw/MlvRdct/8LwTWpl28WX35HIFZkZJzBOURsa65azFrSj40ZGaWcd4jMDPLOO8RmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxv1/jvq7PrQuR/IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('env_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e738630b95736c45865af48faa59aeef505c6ed7a9a98240b21d0125ccc52591"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
